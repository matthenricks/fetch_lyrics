{
 "metadata": {
  "name": "",
  "signature": "sha256:7ff124e6d4b20ded44d45a17dbeda6c85b4ca6be23df0a987628f687eb7b00a9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "from unidecode import unidecode\n",
      "import re\n",
      "\n",
      "from gensim import corpora\n",
      "import nltk\n",
      "from nltk.stem.porter import *\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.tokenize import WordPunctTokenizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Function to clean the text and remove stopwords"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Set up the infrastructure to clean the text\n",
      "\n",
      "packages = ['stopwords']\n",
      "nltk.download(packages)\n",
      "\n",
      "stopset = set(stopwords.words('english'))\n",
      "stemmer = PorterStemmer()\n",
      "def cleanText(column):\n",
      "    tokens = WordPunctTokenizer().tokenize(column)\n",
      "    clean = [token.lower() for token in tokens if token.lower() not in stopset and len(token) > 2]\n",
      "    final = [stemmer.stem(word) for word in clean]\n",
      "    return final"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[nltk_data] Downloading package stopwords to\n",
        "[nltk_data]     /Users/leahxu/nltk_data...\n",
        "[nltk_data]   Package stopwords is already up-to-date!\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set up the stream ability for Mongo :D"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import csv\n",
      "import datetime\n",
      "import string \n",
      "import re\n",
      "import pymongo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Database: lyrics\n",
      "# Collection: songs\n",
      "# Collection: errors\n",
      "from pymongo import MongoClient \n",
      "client = MongoClient('localhost', 27017)\n",
      "db = client.lyrics\n",
      "top_songs = db.songs\n",
      "\n",
      "print top_songs.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "20811\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Switch to our working directory and set up our input and out put paths,\n",
      "# as well as our settings and training file locations\n",
      "\n",
      "# Set up the dictionary\n",
      "dictionary = corpora.Dictionary()\n",
      "\n",
      "selection = top_songs.find({})\n",
      "\n",
      "y = 0\n",
      "i = 0\n",
      "\n",
      "for row in selection:\n",
      "    column = unidecode(row['lyrics'])\n",
      "    column = re.sub('  +', ' ', column)\n",
      "    column = re.sub('\\n', ' ', column)\n",
      "    column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
      "    if column != \"\":\n",
      "        myString = \"\"\n",
      "        for x in cleanText(column):\n",
      "            myString += x + ' '\n",
      "        dictionary.add_documents([myString.split()])\n",
      "\n",
      "    i += 1\n",
      "    if i > 100:\n",
      "        print y\n",
      "        y += 1\n",
      "        i = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dictionary.num_docs\n",
      "print dictionary.num_nnz\n",
      "print dictionary.num_pos\n",
      "print dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary.save('main_dictionary.mm')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a corpus for the listing of songs to compress it for the future"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dict2 = corpora.Dictionary.load('main_dictionary.mm')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dict2.filter_extremes(no_above=0.05)\n",
      "dict2.filter_extremes(no_below=25)\n",
      "dict2.compactify()\n",
      "print dict2.num_docs\n",
      "print dict2.num_nnz\n",
      "print dict2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "0\n",
        "Dictionary(0 unique tokens: [])\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dict2.save('reduced_dictionary.mm')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print dict2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dictionary(0 unique tokens: [])\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}